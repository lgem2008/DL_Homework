{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1F8CjIIV-fJDXrgzXsmkgoLrV_mGFDYbe","authorship_tag":"ABX9TyOIeN8nT1aU2jF5rMOwiHG6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fk5svng5Sf9v","executionInfo":{"status":"ok","timestamp":1745641497930,"user_tz":-480,"elapsed":553,"user":{"displayName":"John","userId":"04362893704005141887"}},"outputId":"5f75823f-2862-48a4-9bb6-c178bc2e03db"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL_Homework/DL_2st\n"]}],"source":["%cd /content/drive/MyDrive/DL_Homework/DL_2st"]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from transformers import ViTForImageClassification, ViTFeatureExtractor\n","from torch.cuda.amp import GradScaler, autocast\n","from tqdm import tqdm\n","\n","# 使用 CUDA 或 CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 数据预处理\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# 加载 CIFAR - 10 数据集\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# 创建数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 使用 HuggingFace 的 ViT 模型和特征提取器\n","feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n","model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=10)\n","\n","# 将模型移到适当的设备（GPU 或 CPU）\n","model.to(device)\n","\n","# 训练设置\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)  # 使用较低的学习率\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# 混合精度训练所需的缩放器\n","scaler = GradScaler()\n","\n","# 训练和评估循环\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    # 训练阶段\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Training', unit='batch')\n","    for images, labels in train_pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # 混合精度训练\n","        with autocast():\n","            outputs = model(images).logits\n","            loss = criterion(outputs, labels)\n","\n","        # 反向传播和更新参数\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # 统计训练准确率\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","        running_loss += loss.item()\n","\n","        # 释放不必要的变量\n","        del images, labels, outputs, loss\n","        torch.cuda.empty_cache()\n","\n","        # 更新进度条信息\n","        train_pbar.set_postfix({'Loss': running_loss / (train_pbar.n + 1), 'Accuracy': correct_train / total_train * 100})\n","\n","    # 在训练集上的准确率\n","    train_acc = correct_train / total_train * 100\n","\n","    # 评估阶段\n","    model.eval()\n","    correct_test = 0\n","    total_test = 0\n","    test_pbar = tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Testing', unit='batch')\n","    with torch.no_grad():\n","        for images, labels in test_pbar:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images).logits\n","            _, preds = torch.max(outputs, 1)\n","            correct_test += (preds == labels).sum().item()\n","            total_test += labels.size(0)\n","\n","            # 更新进度条信息\n","            test_pbar.set_postfix({'Accuracy': correct_test / total_test * 100})\n","\n","    # 在测试集上的准确率\n","    test_acc = correct_test / total_test * 100\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs} | Train Accuracy: {train_acc:.2f}% | Test Accuracy: {test_acc:.2f}%\")\n","\n","    # 每隔 5 个 epoch 保存一次模型\n","    if (epoch + 1) % 1 == 0:\n","        save_path = f\"checkpoints/vit_epoch_{epoch + 1}.pth\"\n","        torch.save(model.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch + 1} as {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"BEH6q6Z6SnWU","executionInfo":{"status":"error","timestamp":1745641237052,"user_tz":-480,"elapsed":2984,"user":{"displayName":"John","userId":"04362893704005141887"}},"outputId":"b765446b-9236-4fa1-f034-e9d8813bd09f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 5020 has 14.74 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 378.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7b6c5ba065b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 将模型移到适当的设备（GPU 或 CPU）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 训练设置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3108\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3109\u001b[0m                 )\n\u001b[0;32m-> 3110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 5020 has 14.74 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 378.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from transformers import ViTForImageClassification, ViTFeatureExtractor\n","from torch.cuda.amp import GradScaler, autocast\n","from tqdm import tqdm\n","import os\n","\n","# 使用 CUDA 或 CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 数据预处理\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# 加载 CIFAR - 10 数据集\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# 创建数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 使用 HuggingFace 的 ViT 模型和特征提取器\n","feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n","model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=10)\n","\n","# 将模型移到适当的设备（GPU 或 CPU）\n","model.to(device)\n","\n","# 训练设置\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)  # 使用较低的学习率\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# 混合精度训练所需的缩放器\n","scaler = GradScaler()\n","\n","# 训练和评估循环\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    # 训练阶段\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Training', unit='batch')\n","    for images, labels in train_pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # 混合精度训练\n","        with autocast():\n","            outputs = model(images).logits\n","            loss = criterion(outputs, labels)\n","\n","        # 反向传播和更新参数\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # 统计训练准确率\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","        running_loss += loss.item()\n","\n","        # 释放不必要的变量\n","        del images, labels, outputs, loss\n","        torch.cuda.empty_cache()\n","\n","        # 更新进度条信息\n","        train_pbar.set_postfix({'Loss': running_loss / (train_pbar.n + 1), 'Accuracy': correct_train / total_train * 100})\n","\n","    # 在训练集上的准确率\n","    train_acc = correct_train / total_train * 100\n","\n","    # 评估阶段\n","    model.eval()\n","    correct_test = 0\n","    total_test = 0\n","    test_pbar = tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Testing', unit='batch')\n","    with torch.no_grad():\n","        for images, labels in test_pbar:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images).logits\n","            _, preds = torch.max(outputs, 1)\n","            correct_test += (preds == labels).sum().item()\n","            total_test += labels.size(0)\n","\n","            # 更新进度条信息\n","            test_pbar.set_postfix({'Accuracy': correct_test / total_test * 100})\n","\n","    # 在测试集上的准确率\n","    test_acc = correct_test / total_test * 100\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs} | Train Accuracy: {train_acc:.2f}% | Test Accuracy: {test_acc:.2f}%\")\n","\n","    # 每隔 1 个 epoch 保存一次模型\n","    if (epoch + 1) % 1 == 0:\n","        save_dir = \"checkpoints\"\n","        if not os.path.exists(save_dir):\n","            os.makedirs(save_dir)\n","        save_path = f\"{save_dir}/vit_epoch_{epoch + 1}.pth\"\n","        torch.save(model.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch + 1} as {save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8v8GUmbUjD7","outputId":"a8c21d71-dffd-4567-bac1-badc1340bc4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n","Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-16-880c0420a497>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","Epoch 1/10 Training:   0%|          | 0/782 [00:00<?, ?batch/s]<ipython-input-16-880c0420a497>:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n","Epoch 1/10 Training: 100%|██████████| 782/782 [09:13<00:00,  1.41batch/s, Loss=0.768, Accuracy=93.1]\n","Epoch 1/10 Testing: 100%|██████████| 157/157 [02:01<00:00,  1.30batch/s, Accuracy=97.6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 | Train Accuracy: 93.06% | Test Accuracy: 97.56%\n","Model saved at epoch 1 as checkpoints/vit_epoch_1.pth\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10 Training: 100%|██████████| 782/782 [09:11<00:00,  1.42batch/s, Loss=0.171, Accuracy=98.8]\n","Epoch 2/10 Testing: 100%|██████████| 157/157 [02:01<00:00,  1.30batch/s, Accuracy=97.9]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10 | Train Accuracy: 98.83% | Test Accuracy: 97.90%\n","Model saved at epoch 2 as checkpoints/vit_epoch_2.pth\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10 Training: 100%|██████████| 782/782 [09:14<00:00,  1.41batch/s, Loss=0.0838, Accuracy=99.6]\n","Epoch 3/10 Testing: 100%|██████████| 157/157 [02:01<00:00,  1.29batch/s, Accuracy=98]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10 | Train Accuracy: 99.55% | Test Accuracy: 98.01%\n","Model saved at epoch 3 as checkpoints/vit_epoch_3.pth\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10 Training: 100%|██████████| 782/782 [09:14<00:00,  1.41batch/s, Loss=0.0482, Accuracy=99.8]\n","Epoch 4/10 Testing: 100%|██████████| 157/157 [02:00<00:00,  1.30batch/s, Accuracy=98.1]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10 | Train Accuracy: 99.75% | Test Accuracy: 98.11%\n","Model saved at epoch 4 as checkpoints/vit_epoch_4.pth\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10 Training:  88%|████████▊ | 685/782 [08:06<01:08,  1.43batch/s, Loss=0.0311, Accuracy=99.8]"]}]},{"cell_type":"code","source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMj1M-8KVmtn","executionInfo":{"status":"ok","timestamp":1745641444624,"user_tz":-480,"elapsed":8257,"user":{"displayName":"John","userId":"04362893704005141887"}},"outputId":"3b81037e-3052-4f83-c712-e538fc84cfd0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=e67deb4f6a764b235d0c1682ad8941e755f7d4900ae0d99be7be1c4f3fec151b\n","  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (4.12.2)\n"]}]},{"cell_type":"code","source":["import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq8UbyF8VqDb","executionInfo":{"status":"ok","timestamp":1745641574111,"user_tz":-480,"elapsed":21,"user":{"displayName":"John","userId":"04362893704005141887"}},"outputId":"37d05519-e927-4a82-c246-3317985a88d9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Gen RAM Free: 10.3 GB  |     Proc size: 2.3 GB\n","GPU RAM Free: 13046MB | Used: 2048MB | Util  13% | Total     15360MB\n"]}]},{"cell_type":"code","source":["import gc\n","gc.collect() # Python thing\n","# torch.cuda.empty_cache() # PyTorch thing\n","with torch.no_grad():\n","    torch.cuda.empty_cache()"],"metadata":{"id":"75I6Fs4mVzH6","executionInfo":{"status":"ok","timestamp":1745641578284,"user_tz":-480,"elapsed":7,"user":{"displayName":"John","userId":"04362893704005141887"}}},"execution_count":14,"outputs":[]}]}